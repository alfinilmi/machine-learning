# -*- coding: utf-8 -*-
"""Proyek 1_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GzxebdjbtitZRzP4NzoTIY7rTBbO2crP

*   Nama : Alfin Muhammad Ilmi
*   Kelas : M06
*   M299X0762
"""

import pandas as pd

d1 = pd.read_csv('train.csv')
d2 = pd.read_csv('test.csv')
df = pd.concat([d1, d2])

df.head()

"""Keterangan Class :
* 1-World 
* 2-Sports
* 3-Business
* 4-Sci/Tech
"""

df['News'] = df['Title'] + ' ' + df['Description']
df.head()

df = df.drop(columns=['Title','Description'])
df

category = pd.get_dummies(df['Class Index'])
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='Class Index')
df_baru

news = df_baru['News'].values
label = df_baru[[1, 2, 3, 4]].values

from sklearn.model_selection import train_test_split
news_latih, news_val, label_latih, label_val = train_test_split(news, label, test_size=0.2)

"""# Data Cleaning

## Membuat lowercase
"""

df['News'] = df['News'].apply(
    lambda data : data.lower()
)
df

"""## Menghilangkan tanda baca"""

import string

def remove_tandabaca(text) : 
  nws = str.maketrans('', '', string.punctuation)
  return text.translate(nws)

df['News'] = df['News'].apply(
    lambda data : remove_tandabaca(data)
)
df

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=8000, oov_token='<oov>')
tokenizer.fit_on_texts(news_latih)
 
sekuens_latih = tokenizer.texts_to_sequences(news_latih)
sekuens_val = tokenizer.texts_to_sequences(news_val)
 
padded_latih = pad_sequences(sekuens_latih,
                             padding='post',
                             maxlen=100,
                             truncating='post') 
padded_val = pad_sequences(sekuens_val,
                           padding='post',
                           maxlen=100,
                           truncating='post')

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=8000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(.2),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(.2),
    tf.keras.layers.Dense(4, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', restore_best_weights=True, patience=20)

num_epochs = 50
batch_size = 128
history = model.fit(padded_latih, label_latih, epochs=num_epochs, batch_size = batch_size,
                    callbacks = [callback], validation_data=(padded_val, label_val), verbose=1)